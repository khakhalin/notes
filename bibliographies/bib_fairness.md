# Fairness in AI, ML, Data Science

#bib #meaning #fairness #interpretability

# Names

* Moritz Hardt
* Cynthia Dwork
* Jon Kleinberg: http://www.cs.cornell.edu/home/kleinber/
* Hima Lakkaraju
* Maxwell Dworkin

# Refs

Barocas, S., Hardt, M., & Narayanan, A. (2017). Fairness in machine learning.
https://fairmlbook.org/
(Reall, a whole book)

Another book (a paper one in this case):
The Ethical Algorithm: The Science of Socially Aware Algorithm Design
by Michael Kearns, Aaron Roth
https://www.amazon.com/Ethical-Algorithm-Science-Socially-Design/dp/0190948205

Shorter tutorial on Fairness:
https://mrtz.org/nips17/#/

The AI Transparency Paradox
Andrew Burt. 2019. Harvard Business Review
https://hbr.org/2019/12/the-ai-transparency-paradox
(On the paradoxical danger of transparency for AI algorithms)

Corbett-Davies, S., & Goel, S. (2018). The measure and mismeasure of fairness: A critical review of fair machine learning. arXiv preprint arXiv:1808.00023.
https://5harad.com/papers/fair-ml.pdf

CSE 291 Section B: Topics in Trustworthy Machine Learning
by Kamalika Chaudhuri
http://cseweb.ucsd.edu/classes/sp20/cse291-b/
Also much shorter video tutorial:
https://vimeo.com/248492174

Slack, D., Hilgard, S., Jia, E., Singh, S., & Lakkaraju, H. (2020, February). Fooling lime and shap: Adversarial attacks on post hoc explanation methods. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (pp. 180-186).
https://arxiv.org/abs/1911.02508

Lakkaraju, H., & Bastani, O. (2020, February). " How do I fool you?" Manipulating User Trust via Misleading Black Box Explanations. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (pp. 79-85).
https://arxiv.org/abs/1911.06473
About how by manipulating features (essentially, rotating in a space of features we can make unethical AI approaches seem ethical, and the other way around)

Srivastava, M., Heidari, H., & Krause, A. (2019, July). Mathematical notions vs. human perception of fairness: A descriptive approach to fairness for machine learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2459-2468).
https://arxiv.org/pdf/1902.04783.pdf

Heidari, H., Ferrari, C., Gummadi, K., & Krause, A. (2018). Fairness behind a veil of ignorance: A welfare analysis for automated decision making. In Advances in Neural Information Processing Systems (pp. 1265-1276).
https://www.cs.cornell.edu/~hh732/heidari2018fairness.pdf

Raghu, M., Blumer, K., Corrado, G., Kleinberg, J., Obermeyer, Z., & Mullainathan, S. (2019). The algorithmic automation problem: Prediction, triage, and human effort. arXiv preprint arXiv:1903.12220.
https://arxiv.org/abs/1903.12220

"Fair Questions". Youtube Lecture by Cynthia Dwork
https://www.youtube.com/watch?v=RAZJx0rpF_0

Interpretability and Explainability in Machine Learning
COMPSCI 282BR, Harvard University. Fal 2019 class
https://interpretable-ml-class.github.io/

Kleinberg, J., Lakkaraju, H., Leskovec, J., Ludwig, J., & Mullainathan, S. (2018). Human decisions and machine predictions. The quarterly journal of economics, 133(1), 237-293.
https://www.nber.org/papers/w23180

Kleinberg, J., Mullainathan, S., & Raghavan, M. (2016). Inherent trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807.
https://arxiv.org/abs/1609.05807

Raghu, M., Blumer, K., Corrado, G., Kleinberg, J., Obermeyer, Z., & Mullainathan, S. (2019). The algorithmic automation problem: Prediction, triage, and human effort. arXiv preprint arXiv:1903.12220.
https://arxiv.org/abs/1903.12220

Subbaswamy, A., Schulam, P., & Saria, S. (2019, April). Preventing failures due to dataset shift: Learning predictive models that transport. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 3118-3127).
https://arxiv.org/abs/1812.04597

Schulam, P., & Saria, S. (2019). Can you trust this prediction? Auditing pointwise reliability after learning. arXiv preprint arXiv:1901.00403.
https://arxiv.org/abs/1901.00403

Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., ... & Wood, A. (2017). Accountability of AI under the law: The role of explanation. arXiv preprint arXiv:1711.01134.
https://arxiv.org/abs/1711.01134

Pierson, E., Simoiu, C., Overgoor, J., Corbett-Davies, S., Jenson, D., Shoemaker, A., ... & Goel, S. (2020). A large-scale analysis of racial disparities in police stops across the United States. Nature human behaviour, 1-10.
https://5harad.com/papers/100M-stops.pdf

Jung, J., Goel, S., & Skeem, J. (2020). The limits of human predictions of recidivism. Science advances, 6(7), eaaz0652.
https://advances.sciencemag.org/content/6/7/eaaz0652

Lakkaraju, H., Kamar, E., Caruana, R., & Horvitz, E. (2017, February). Identifying unknown unknowns in the open world: Representations and policies for guided exploration. In Thirty-First AAAI Conference on Artificial Intelligence.
https://arxiv.org/abs/1610.09064
Related: [[04_Features]]

Ramakrishnan, R., Kamar, E., Dey, D., Shah, J., & Horvitz, E. (2018). Discovering blind spots in reinforcement learning. arXiv preprint arXiv:1805.08966.
https://arxiv.org/abs/1805.08966

Pierson, E., Corbett-Davies, S., & Goel, S. (2018, March). Fast threshold tests for detecting discrimination. In International Conference on Artificial Intelligence and Statistics (pp. 96-105).
https://arxiv.org/abs/1702.08536

Corbett-Davies, S., Pierson, E., Feller, A., Goel, S., & Huq, A. (2017, August). Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining (pp. 797-806).
https://arxiv.org/abs/1701.08230

Kaur, H., Nori, H., Jenkins, S., Caruana, R., Wallach, H., & Wortman Vaughan, J. (2020, April). Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1-14).
http://www.jennwv.com/papers/interp-ds.pdf

Yin, M., Wortman Vaughan, J., & Wallach, H. (2019, May). Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 chi conference on human factors in computing systems (pp. 1-12).
http://www.jennwv.com/papers/accuracy-trust.pdf

Zafar, M. B., Valera, I., Rogriguez, M. G., & Gummadi, K. P. (2017, April). Fairness constraints: Mechanisms for fair classification. In Artificial Intelligence and Statistics (pp. 962-970).
https://arxiv.org/abs/1507.05259

Grgić-Hlača, N., Engel, C., & Gummadi, K. P. (2019). Human decision making with machine assistance: An experiment on bailing and jailing. Proceedings of the ACM on Human-Computer Interaction, 3(CSCW), 1-25.
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3465622

Ribeiro, M. T., Singh, S., & Guestrin, C. (2016, August). " Why should I trust you?" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 1135-1144).
https://arxiv.org/abs/1602.04938

Subramanian, S., Bogin, B., Gupta, N., Wolfson, T., Singh, S., Berant, J., & Gardner, M. (2020). Obtaining Faithful Interpretations from Compositional Neural Networks. arXiv preprint arXiv:2005.00724.
https://arxiv.org/pdf/2005.00724.pdf

Chouldechova, A., & Roth, A. (2018). The frontiers of fairness in machine learning. arXiv preprint arXiv:1810.08810.
https://arxiv.org/abs/1810.08810