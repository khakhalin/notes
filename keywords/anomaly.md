# Anomaly detection

Parents: [[03_Classification]]
See also: [[time-series]], [[augmentation]], [[embedding]]

#classification


Essentially, a binary classification problem. We assume that most of the data is produced by a certain process, but every now and then we have an **anomaly**: a point produced by a different process. We need to identify these "stray points" (aka outliers, or "surprise"). But then on top of this binary classifier we may of course be intrested in a probability score; multi-class classification labels, etc.

Example applications: fraud detection (banks, credit cards, phones etc.), attack detection (in cybersecurity), insider training, novelty detection (important for self-supervised learning), public health anomalies, industrial damage and fault detection, data validation, security level for AI tools (e.g. medical systems, autonomous driving).

Def: An anomaly is an observation that considerably deviates from some concept of **normalcy**

Most approaches try to approximate the distribution for the "main set of data", and then see if new points are likely to come from this distribution. This can be done parametrically (e.g. with Z-scores), using Bayesian statistics, unsupervised methods such as [[clustering]], supervised classifiers, such as [[05_Ensembles]], or fancy semi-supervised approaches, such as [[autoencoder]]s or discriminators from a [[gan]] network. But the underlying assumption is that the probability that the anomalous point was generated by a "normal process" is very low (with some threshold).

**Concentration assumption**: the region in which the normal data lives can be bounded.

Some practical complications:
* **Behavior drift.** The distribution of normal behavior often changes, evolves over time
* Typically, **the data is unlabeled**, so supervised techniques may be tricky, as labeleing often requires human intervention, and thus is very expensive.
* When some labels are available, there's an **extreme imbalance of classes** (examples of labeled anomalies are always very rare compared to the number of "normal points")
* Individual variables may be distributed very differently (continuous, categorical, etc.).
* **Context** (in time, space, etc. - see below)

> It seems to me that in general, anomaly detection seems to be well-posed for [[11_RL]] and various semi-supervised ([[08_Unsupervised]]) approaches, as the number of labeled outliers is typically very small, and also does not cover the full spectrum of possibilities (it's hard to predict how things may go wrong), while the number of labeled "legal points" is relatively large. It seems that ideally you'd want a method that mostly relies on "legal points" to catch some patterns, but then incorporates labeled outliers to further improve the picture.

Tips and tricks:
* For a mix of continuous and categorical values, we may either try an [[embedding]] (see below), or switch to a pairwise distance representation (using Manhattan distance for example), and then either project from distances to a low-D space, or to keep working with distances (see KNN-like methods below)
* Instead of explicitly modeling a distribution, we can train an [[autoencoder]] to learn an [[embedding]] for valid states, and then either classifying in the space of this embedding, or directly relying on the encoding-decoding error for anomalous points, under an assumption that anomalous points cannot be represented by this network as well as valid points. (This approach also appears to be called "replicator networks")
    * Back in the 1990s people even tried to use Kolmogorov komplexity for sequences of events with the same motivation ("legal" sequences have more structure, and so can be zipped to smaller files! See Chandola2009 for refs)
    * In the 2000s they also tried to generate embeddings by taking consecutive points of a time-series, calculating distances, interpreting it as a adjacency matrix of a graph, and then looking at this graph's eigenvectors ðŸ˜±
* As for anomaly detection not only the values of valid learning points, but also their concentration is important, one can do something like a reversed [[knn]] method: to look at the number of good valid points in the immediate vicinity of the point of interest, or the size of the vicinity (hypersfhere) necessary to catch a certain number (share) of training points. This group of approaches used to be called "Peer group analysis", "relative density" approach, or "Local Outlier Factor".
* Partitions and kernels: instead of defining areas as a decision boundary or in a KNN way, we can optimize "safe space" description by placing some archetypical values in it, and looking at a distance to the closest archetype. Reduces the problem to a bunch of local classifications for the vicinity of each archetype (here "archetype" is my word, not something I read; ppl in the 2000s seem to have mostly called these points "parititions")
* A very simplified variant of partitioning is calculating probabilities on a grid (high-D hypergrid)
* In early 2000s it was trendy to play with manually constructed metrics, like Connectivity-based Outlier Factor (COF), Outlier Detecton using In-Degree (ODIN), Multi-Granuality Deviation (MDEF), Cluster-Based Local Outlier Factor (CBLOF) etc, but I would expect these to become less valuable today
* For weird data, the key is either in creating an [[embedding]], or in working from distances. Say, for protein sequences, people used some "Probabilistic Suffix Trees" that define a distance between 2 sequences.
* Semi-supervised learning, including synthetic data and data [[augmentation]]

# Context

Before, we mostly imagined individual anomalous observations, or **point anomalies**. But one can also speak of:

**Contextual anomalies**: Often it's not the value (vector) itself that is sketchy, but rather the value in the context (time, spatial, neghboring on a graph). [[time-series]] contextual anomalies are the most common, and both neighboring values of the signal, and values of other signals for this period of time provide the context. (Example: a sudden increase in credit card spending is normal before Xmas, but may not be normal outside of the season. Any spatial image-like data is another obvious example)

**Collective anomalies**: when the values themsevelves are ok and changing smoothly, but the shape of points taken together is weird (say, a cardiogram missing a beat, or a any other pathological sequence of events in a stream of events).

One way to deal with context is to try to cancel it, thus switching to a simpler task of point anomalies (almost like subtracting a local average). Or we can move to a space of local distances, or an autogression matrix for [[time-series]], to somehow characterize the context as a whole (embedding of an embedding?). Modeling of a generative process with [[hmm]] was also popular.

**Hierarchical anomalies**: for complex data, there may be a distinctino between **sensory** and **semantic** anomalies, or about low- and high-order structure in the data. Images and text provide an obvious example (typos/noise vs sense).

# DL for anomaly detection

See: [[06_DL]]

"Classic" (not-DL) anomaly detection is now sometimes called "shallow", while DL-based is obviously "deep". Can be used for images, text, and other complex data.

> There's this statement that for tabular data tree-based approaches typically outperform DL. Does it mean that in business setting, for relatively low-D tabular data, shallow approaches are preferable?



# References

https://en.wikipedia.org/wiki/Anomaly_detection

Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58. https://conservancy.umn.edu/bitstream/handle/11299/215731/07-017.pdf?sequence=1
The most cited review paper ever. Provides an interesting (but of course dated) summary of domain-specific tricks and preferences.

Ruff, L., Kauffmann, J. R., Vandermeulen, R. A., Montavon, G., Samek, W., Kloft, M., ... & MÃ¼ller, K. R. (2021). A unifying review of deep and shallow anomaly detection. Proceedings of the IEEE, 109(5), 756-795.
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347460


