# Consciousness

#meaning #psych

# My thoughts and theories

Basically, as I wrote, what we perceive as "conscious" is a very specific anthropocentric calculation. It's 1) fairly fancy, 2) the subject hesitates (realizes, reflects), and 3) drastically changes the strategy. So what feels "conscious" to us is when system 2 (GOFAI, or Marcus-style symbolic logic) detects that system 1 (intuition, more FF NNs) fails, and corrects it. Like, forcing a change in strategy, inferring info (mirror test, theory of mind) etc.

The problem with this definition is that it's obviously not transferrable across architectures and scales of hardware efficiency. Like, Alpha Go almost does it, but we don't perceive it as conscious as it's too "simple" to us. Conversely a good enough ANN may do it without relying on symbolic logic (GPT almost did it, in a way, producing what almost felt like "artifacts of consciousness" without any deliberate self-reflection)