# Notes on graphs notebook, Jul 23 2020

#graphs

Parent: [[deep_graphs]]

> A discussion of this notebook from Leskovec's course on graphical models:
https://colab.research.google.com/drive/1DIQm9rOx2mT1bZETEeVUThxcrP1RKqAn

Not that easy to install. On one machine, geometric takes ~20 min to install, on another one pyg_nn fails.

In pytorch, ot create a model we need to inherit to `nn.Module`, then 3 layers. Auto-diffentiating. We only describe a forward pass, it auto-calculates gradients.

28 windows 3x3. 32 filters, and batch = 32. Then we flatten it, do 2 dense layers; relu after the 1st, softmax at the end. Output has the dimensionality of batch_size Ã— number_of_classes (in our case, 10).

Next cell: just show how numpy transforms to Torch, and how to show that it needs to be processed on a GPU (that's this `cude:0` thing). `@` denotes matrix product (Torch thing).

Next cells: checks if a GPU is present; 'moves' it to a device, defines loss and optimizer.

`optimizer.zero_grad()` - zeros gradient, to make batches independent. Right? We're not sure. Does it zero the momentum of ADAM? Not sure.

`loss.backward()` calculates the gradients. `optimizer.step()` updates the weights. Then takes one element of loss, casts it to numpy and saves. Then calculates accuracy in a slightly strange way (they calculate mean for each batch, and they later apparently they do mean() across an epoch or something, so they get `mean(mean())`, and that's weird.)

A claim that the next loop is weird.

Then starts graph module itself. `GCNConv` and `GINConv` seem to be the key, but they seem to directly implement their papers.

Strange code: set emb=x in a loop, then use it only once. Probably just bad code.

Seem to be two modes of operation: proces entire graph, or classify nodes. If entire graph, mean-pooling at the end. We are not sure what's happening tho, and it's not even clear how the data looks. Like, what's classified? We don't know. Labels on nodes? which labels?

Next cell seems to pre-process the adjacency matrix in some way (e.g. it seems to remove loops, aka self-connections). And they they seem to be doing message propagation (just based on the name `propagate`). Inherited from a base class.

The comment inside `forward` method says `add self-loops`, but the method is called `remove self-loops`. Probably just a mistake.

Later a method `message` receives an input `x_j`, then does something, and just returns `x_j`. Like, why? Probably a mistake (probably just leftover code from a more complex use case).

`Train` part: starts with loading a loader appropriate for a task (node or graph). What dataset they use is unclear. Loss is a negative local something loss (`nll`).

`with torch.np_grad()`: to test properly, we need to start with fully empty gradients (unlike for training).

Everything `ngrok` didn't work for us. Is it some custom local util they use? They are clearly trying to generate some reports though.

Then they load some existing graph dataset (Planetoid cora? Something about enzymes? Not clear. Or is it IMDB - movies? What??).

Their visualization seems broken, as their model somehow returns more classes (in the prediction `pred`) that they account for in their color vector. They first make high-dim embeddings, then tSNE them to 2D.

Then goes unsupervised. `recon_loss` sounds like something about reconnecting edges? The model `GAE` sounds like attention encoder.

Conclusion: we don't like it. We want to write our own toy example. We would need some non-random graphs tho. (Personally, I'd probablyh go with Karate club, but other fellas seem to prefer larger graphs).